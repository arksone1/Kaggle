#%%
import pandas as pd
import numpy as np
import reduce_mem
import gc


#%%
train = pd.read_csv('train_V2.csv')
train = reduce_mem.reduce_mem_usage(train)
test = pd.read_csv('test_V2.csv')
test = reduce_mem.reduce_mem_usage(test)

#%%
all_data = train.append(test, sort=False).reset_index(drop=True)
del train, test
gc.collect()

#%%
match = all_data.groupby('matchId')
all_data['killPlacePerc'] = match['kills'].rank(pct=True).values
all_data['walkDistancePerc'] = match['walkDistance'].rank(pct=True).values

#%%
def fillInf(df, val):
    numcols = df.select_dtypes(include='number').columns
    cols = numcols[numcols != 'winPlacePerc']
    df[df == np.Inf] = np.NaN
    df[df == np.NINF] = np.NaN
    for c in cols: df[c].fillna(val, inplace=True)

#%%
all_data['_healthItems'] = all_data['heals'] + all_data['boosts']
all_data['_totalDistance'] = all_data['rideDistance'] + all_data['swimDistance'] + all_data['walkDistance']
all_data['_headshotKillRate'] = all_data['headshotKills'] / all_data['kills']
all_data['_killPlaceOverMaxPlace'] = all_data['killPlace'] / all_data['maxPlace']
all_data['_killsOverWalkDistance'] = all_data['kills'] / all_data['walkDistance']
all_data['_killsOverDistance'] = all_data['kills'] / all_data['_totalDistance']
all_data['cheater'] = (all_data['kills']>3) & (all_data['headshotKills']/all_data['kills']>=0.8)

fillInf(all_data, 0)


#%%
all_data.drop(['boosts','heals','killStreaks','DBNOs', 'headshotKills','roadKills','vehicleDestroys', 'rideDistance','swimDistance','matchDuration', 'rankPoints','killPoints','winPoints'], axis=1, inplace=True)

#%%
match = all_data.groupby(['matchId'])
group = all_data.groupby(['matchId', 'groupId', 'matchType'])

agg_col = list(all_data.columns)
sum_col = ['kills', 'killPlace', 'damageDealt', 'walkDistance', '_healthItems']
exclude_agg_col = ['Id', 'matchId', 'groupId', 'matchType', 'maxPlace', 'numGroups', 'winPlacePerc']
for c in exclude_agg_col:
    agg_col.remove(c)
print(agg_col)


#%%
match_data = pd.concat([
    match.size().to_frame('m.players'), 
    match[sum_col].sum().rename(columns=lambda s: 'm.sum.' + s), 
    match[sum_col].max().rename(columns=lambda s: 'm.max.' + s), 
    match[sum_col].mean().rename(columns=lambda s: 'm.mean.' + s) ], axis=1).reset_index()
match_data = pd.merge(match_data, group[sum_col].sum().rename(columns=lambda s: 'sum.' + s).reset_index())
match_data = reduce_mem.reduce_mem_usage(match_data)



#%%
minKills = all_data.sort_values(['matchId', 'groupId', 'kills', 'killPlace']).groupby(['matchId', 'groupId', 'kills']).first().reset_index()

#%%
for n in np.arange(5):
    c = 'kills_' + str(n) + '_Place'
    nKills = (minKills['kills']==n)
    minKills.loc[nKills, c] = minKills[nKills].groupby(['matchId'])['killPlace'].rank().values
    match_data = pd.merge(match_data, minKills[nKills][['matchId', 'groupId', c]], how='left')
match_data = reduce_mem.reduce_mem_usage(match_data)
del minKills, nKills


#%%
all_data = pd.concat([
    group.size().to_frame('players'), 
    group.mean(), 
    group[agg_col].max().rename(columns=lambda s: 'max.' + s), 
    group[agg_col].min().rename(columns=lambda s: 'min.' + s)], axis=1).reset_index()
all_data = reduce_mem.reduce_mem_usage(all_data)


#%%
all_data = pd.merge(all_data, match_data)
del match_data
gc.collect()

#%%
all_data['enemy.players'] = all_data['m.players'] - all_data['players']
for c in sum_col:
    all_data['enemy.' + c] = (all_data['m.sum.' + c] - all_data['sum.' + c]) / all_data['enemy.players']
    all_data['p.max_msum.' + c] = all_data['max.' + c] / all_data['m.sum.' + c]
    all_data['p.max_mmax.' + c] = all_data['max.' + c] / all_data['m.max.' + c]
    all_data.drop(['m.sum.' + c, 'm.max.' + c], axis=1, inplace=True)

fillInf(all_data, 0)
print(all_data.shape)


#%%
numcols = all_data.select_dtypes(include='number').columns.values
numcols = numcols[numcols != 'winPlacePerc']
match = all_data.groupby('matchId')
matchRank = match[numcols].rank(pct=True).rename(columns=lambda s: 'rank.' + s)
all_data = reduce_mem.reduce_mem_usage(pd.concat([all_data, matchRank], axis=1))
rank_col = matchRank.columns
del matchRank
gc.collect()


#%%
match = all_data.groupby('matchId')
matchRank = match[rank_col].max().rename(columns=lambda s: 'max.' + s).reset_index()
all_data = pd.merge(all_data, matchRank)
for c in numcols:
    all_data['rank.' + c] = all_data['rank.' + c] / all_data['max.rank.' + c]
    all_data.drop(['max.rank.' + c], axis=1, inplace=True)
del matchRank


gc.collect()

print(all_data.shape)

#%%
constant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]
print('drop columns:', constant_column)
all_data.drop(constant_column, axis=1, inplace=True)


#%%
mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'
all_data['matchType'] = all_data['matchType'].apply(mapper)
all_data = pd.concat([all_data, pd.get_dummies(all_data['matchType'])], axis=1)
all_data.drop(['matchType'], axis=1, inplace=True)
all_data['matchId'] = all_data['matchId'].apply(lambda x: int(x, 16))
all_data['groupId'] = all_data['groupId'].apply(lambda x: int(x, 16))


#%%
cols = [col for col in all_data.columns if col not in ['Id', 'matchId', 'groupId']]
for i, t in all_data.loc[:, cols].dtypes.iteritems():
    if t == object:
        all_data[i] = pd.factorize(all_data[i])[0]
all_data = reduce_mem.reduce_mem_usage(all_data)


#%%
X_train = all_data[all_data['winPlacePerc'].notnull()].reset_index(drop=True)
X_test = all_data[all_data['winPlacePerc'].isnull()].drop(['winPlacePerc'], axis=1).reset_index(drop=True)
del all_data
gc.collect()

Y_train = X_train.pop('winPlacePerc')
X_test_grp = X_test[['matchId', 'groupId']].copy()
train_matchId = X_train['matchId']
X_train.drop(['matchId', 'groupId'], axis=1, inplace=True)
X_test.drop(['matchId', 'groupId'], axis=1, inplace=True)


#%%
from sklearn.model_selection import GroupKFold
from sklearn.preprocessing import minmax_scale
import lightgbm as lgb

params={'learning_rate':0.1, 
        'objective':'mae',
        'metric':'mae', 
        'num_leaves':31, 
        'verbose':1, 
        'random_state':42,
        'bagging_fraction':0.7,
        'feature_fraction':0.7}
reg = lgb.LGBMRegressor(**params, n_estimators=5000)
reg.fit(X_train, Y_train)
pred = reg.predict(X_test, num_iteration=reg.best_iteration_)


#%%
#X_test_grp['_nofit.winPlacePerc'] = pred
X_test_grp['winPlacePerc'] = pred


#%%
test = pd.read_csv('test_V2.csv')
test['matchId'] = test['matchId'].apply(lambda x: int(x,16))
test['groupId'] = test['groupId'].apply(lambda x: int(x,16))


#%%
submission = pd.merge(test, X_test_grp)
submission = submission[['Id', 'winPlacePerc']]

#%%
submission.to_csv('submission.csv', index=False)
